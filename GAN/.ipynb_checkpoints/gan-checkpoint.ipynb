{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8499\n",
      "(40, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "workDir = '/mnt/c/users/llave/Documents/CMS/'\n",
    "data = np.load(workDir+'images_DYJets50V2.npy')\n",
    "print(len(data))\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    input = Input(img_shape)\n",
    "    x = Conv2D(32*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(x)\n",
    "    x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
    "    x = (LeakyReLU(alpha=0.2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(128*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(256*3, kernel_size=(4,4), strides=(1,1), padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    #testing\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(input, out)\n",
    "    print(\"-- Discriminator -- \")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_generator(noise_shape=(100,)):\n",
    "    input = Input(noise_shape)\n",
    "    x = Dense(128 * 10 * 10, activation=\"relu\")(input)\n",
    "    x = Reshape((10,10, 128))(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    #upsampling to 20x20\n",
    "    x = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    #upsampling to 40x40\n",
    "    x = Conv2DTranspose(64, (4,4),strides=(2,2), padding='same')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(3, kernel_size=3, padding=\"same\")(x)\n",
    "    out = Activation(\"tanh\")(x)\n",
    "    model = Model(input, out)\n",
    "    print(\"-- Generator -- \")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#plots events\n",
    "def plot_event(eventNum):\n",
    "    \n",
    "    x = events[eventNum]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3)\n",
    "    for i in range(3):\n",
    "        axs[i].imshow(x[:,:,i])\n",
    "        \n",
    "    axs[0].set_title(\"ECAL\")\n",
    "    axs[1].set_title(\"HCAL\")\n",
    "    axs[2].set_title(\"Muon\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#generates and saves 5 random images\n",
    "def save_imgs(generator, epoch, batch):\n",
    "    r, c = 5, 3\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, j], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(workDir+\"images/tracks_%d_%d.png\" % (epoch, batch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Discriminator -- \n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 40, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 96)        4704      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 20, 20, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 20, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 192)       295104    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 11, 11, 192)       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 11, 11, 192)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 192)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 192)       768       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         1180032   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 768)         4719360   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6, 6, 768)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 768)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 27649     \n",
      "=================================================================\n",
      "Total params: 6,229,153\n",
      "Trainable params: 6,228,001\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "-- Generator -- \n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12800)             1292800   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 20, 20, 128)       262272    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 40, 40, 64)        131136    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 40, 40, 3)         1731      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 40, 3)         0         \n",
      "=================================================================\n",
      "Total params: 1,689,219\n",
      "Trainable params: 1,688,579\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build and compile discriminator and generator\n",
    "discriminator = build_discriminator(img_shape=(40,40, 3))\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                               optimizer=Adam(lr=0.0002, beta_1=0.5),\n",
    "                               metrics=['mse'])\n",
    "\n",
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine them\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "real = discriminator(img)\n",
    "combined = Model(z, real)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  8499\n",
      "Number of Batches:  531\n",
      "Number of epochs:  100\n",
      "Epoch 0 Batch 0/531 [D loss: 0.24, mse avg: 0.02] [D mse real: 0.01 D mse fake: 0.03], [G loss: 2.85]\n",
      "Epoch 0 Batch 50/531 [D loss: 0.22, mse avg: 0.01] [D mse real: 0.01 D mse fake: 0.00], [G loss: 4.87]\n",
      "Epoch 0 Batch 100/531 [D loss: -0.24, mse avg: 0.02] [D mse real: 0.03 D mse fake: 0.00], [G loss: 5.81]\n",
      "Epoch 0 Batch 150/531 [D loss: -0.22, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 7.07]\n",
      "Epoch 0 Batch 200/531 [D loss: 0.05, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 7.87]\n",
      "Epoch 0 Batch 250/531 [D loss: -0.05, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 6.36]\n",
      "Epoch 0 Batch 300/531 [D loss: 0.07, mse avg: 0.00] [D mse real: 0.01 D mse fake: 0.00], [G loss: 6.86]\n",
      "Epoch 0 Batch 350/531 [D loss: 0.59, mse avg: 0.12] [D mse real: 0.24 D mse fake: 0.00], [G loss: 56.69]\n",
      "Epoch 0 Batch 400/531 [D loss: 0.34, mse avg: 0.06] [D mse real: 0.11 D mse fake: 0.01], [G loss: 8.99]\n",
      "Epoch 0 Batch 450/531 [D loss: 0.07, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 6.72]\n",
      "Epoch 0 Batch 500/531 [D loss: 0.11, mse avg: 0.03] [D mse real: 0.05 D mse fake: 0.00], [G loss: 13.71]\n",
      "Epoch 1 Batch 0/531 [D loss: 0.50, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 12.63]\n",
      "Epoch 1 Batch 50/531 [D loss: 0.10, mse avg: 0.01] [D mse real: 0.01 D mse fake: 0.00], [G loss: 8.15]\n",
      "Epoch 1 Batch 100/531 [D loss: 0.16, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 17.29]\n",
      "Epoch 1 Batch 150/531 [D loss: 0.26, mse avg: 0.03] [D mse real: 0.07 D mse fake: 0.00], [G loss: 9.83]\n",
      "Epoch 1 Batch 200/531 [D loss: -0.05, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 10.36]\n",
      "Epoch 1 Batch 250/531 [D loss: 0.05, mse avg: 0.01] [D mse real: 0.01 D mse fake: 0.00], [G loss: 11.25]\n",
      "Epoch 1 Batch 300/531 [D loss: -0.01, mse avg: 0.01] [D mse real: 0.01 D mse fake: 0.00], [G loss: 6.58]\n",
      "Epoch 1 Batch 350/531 [D loss: 0.22, mse avg: 0.06] [D mse real: 0.11 D mse fake: 0.00], [G loss: 5.96]\n",
      "Epoch 1 Batch 400/531 [D loss: -0.01, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 9.94]\n",
      "Epoch 1 Batch 450/531 [D loss: 0.23, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 10.90]\n",
      "Epoch 1 Batch 500/531 [D loss: 0.17, mse avg: 0.03] [D mse real: 0.06 D mse fake: 0.01], [G loss: 6.56]\n",
      "Epoch 2 Batch 0/531 [D loss: 0.33, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 7.88]\n",
      "Epoch 2 Batch 50/531 [D loss: -0.02, mse avg: 0.00] [D mse real: 0.01 D mse fake: 0.00], [G loss: 8.20]\n",
      "Epoch 2 Batch 100/531 [D loss: 0.12, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 10.96]\n",
      "Epoch 2 Batch 150/531 [D loss: 0.27, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 6.12]\n",
      "Epoch 2 Batch 200/531 [D loss: 0.16, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 8.06]\n",
      "Epoch 2 Batch 250/531 [D loss: 0.44, mse avg: 0.02] [D mse real: 0.03 D mse fake: 0.00], [G loss: 12.05]\n",
      "Epoch 2 Batch 300/531 [D loss: 0.16, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 15.24]\n",
      "Epoch 2 Batch 350/531 [D loss: 0.14, mse avg: 0.02] [D mse real: 0.03 D mse fake: 0.00], [G loss: 15.57]\n",
      "Epoch 2 Batch 400/531 [D loss: 0.16, mse avg: 0.02] [D mse real: 0.04 D mse fake: 0.00], [G loss: 9.16]\n",
      "Epoch 2 Batch 450/531 [D loss: 0.20, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 11.50]\n",
      "Epoch 2 Batch 500/531 [D loss: 0.21, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 8.97]\n",
      "Epoch 3 Batch 0/531 [D loss: 0.09, mse avg: 0.02] [D mse real: 0.03 D mse fake: 0.00], [G loss: 6.17]\n",
      "Epoch 3 Batch 50/531 [D loss: 0.06, mse avg: 0.01] [D mse real: 0.01 D mse fake: 0.00], [G loss: 10.81]\n",
      "Epoch 3 Batch 100/531 [D loss: 0.66, mse avg: 0.16] [D mse real: 0.32 D mse fake: 0.00], [G loss: 9.38]\n",
      "Epoch 3 Batch 150/531 [D loss: 0.33, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 11.17]\n",
      "Epoch 3 Batch 200/531 [D loss: 0.05, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 9.36]\n",
      "Epoch 3 Batch 250/531 [D loss: 0.09, mse avg: 0.01] [D mse real: 0.03 D mse fake: 0.00], [G loss: 9.69]\n",
      "Epoch 3 Batch 300/531 [D loss: 0.12, mse avg: 0.07] [D mse real: 0.14 D mse fake: 0.00], [G loss: 9.91]\n",
      "Epoch 3 Batch 350/531 [D loss: 0.08, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 10.24]\n",
      "Epoch 3 Batch 400/531 [D loss: 0.10, mse avg: 0.01] [D mse real: 0.02 D mse fake: 0.00], [G loss: 8.07]\n"
     ]
    }
   ],
   "source": [
    "import numpy.random\n",
    "from numpy.random import choice\n",
    "from numpy.random import randn\n",
    "\n",
    "def noisy_labels(y, p_flip):\n",
    "    # determine the number of labels to flip\n",
    "    n_select = int(p_flip * y.shape[0])\n",
    "    # choose labels to flip\n",
    "    flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
    "    # invert the labels in place\n",
    "    y[flip_ix] = 1 - y[flip_ix]\n",
    "    return y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape((n_samples, latent_dim))\n",
    "    return x_input\n",
    "\n",
    "def smooth_positive_labels(y):\n",
    "    return y - 0.3 + (np.random.random(y.shape) * 0.5)\n",
    "\n",
    "def smooth_negative_labels(y):\n",
    "    return y + np.random.random(y.shape) * 0.3\n",
    "\n",
    "X_train = data\n",
    "\n",
    "epochs=100\n",
    "batch_size=16\n",
    "save_interval=1\n",
    "\n",
    "num_examples = X_train.shape[0]\n",
    "num_batches = int(num_examples / float(batch_size))\n",
    "print('Number of examples: ', num_examples)\n",
    "print('Number of Batches: ', num_batches)\n",
    "print('Number of epochs: ', epochs)\n",
    "\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "d_loss = [10,10]\n",
    "g_loss = 10\n",
    "d_loss_array = []\n",
    "g_loss_array = []\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for batch in range(num_batches):\n",
    "\n",
    "        # noise images for the batch\n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "        fake_images = generator.predict(noise)\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "        # real images for batch\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        real_images = X_train[idx]\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        \n",
    "        #testing noisy labels\n",
    "        real_labels = noisy_labels(real_labels,0.05)\n",
    "        real_labels = smooth_positive_labels(real_labels)\n",
    "        fake_labels = smooth_negative_labels(fake_labels)\n",
    "\n",
    "        # Train the discriminator (real classified as 1 and generated as 0)\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train the generator\n",
    "        labels = np.ones((batch_size, 1))\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        #testing gaussian latent space\n",
    "        noise = generate_latent_points(100,batch_size)\n",
    "        \n",
    "        g_loss = combined.train_on_batch(noise, labels)\n",
    "            \n",
    "        d_loss_array.append(d_loss[0])\n",
    "        g_loss_array.append(g_loss)\n",
    "\n",
    "        # Plot the progress\n",
    "        if(batch % 50 == 0):\n",
    "            #print(\"Epoch %d Batch %d/%d [D loss: %.2f, acc avg: %.2f%%] [D acc real: %.2f D acc fake: %.2f], [G loss: %.2f]\" %\n",
    "            #      (epoch, batch, num_batches, d_loss[0], 100 * d_loss[1], d_loss_real[1], d_loss_fake[1],g_loss))\n",
    "             print(\"Epoch %d Batch %d/%d [D loss: %.2f, mse avg: %.2f] [D mse real: %.2f D mse fake: %.2f], [G loss: %.2f]\" %\n",
    "                  (epoch, batch, num_batches, d_loss[0], d_loss[1], d_loss_real[1], d_loss_fake[1],g_loss))\n",
    "    \n",
    "    \n",
    "        if(batch % 50 == 0): save_imgs(generator, epoch, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_loss_array,label='d_loss')\n",
    "plt.plot(g_loss_array,label='g_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
