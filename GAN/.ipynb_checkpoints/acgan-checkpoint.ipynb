{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1555, 40, 40, 3) (1007, 40, 40, 3) (2562, 40, 40, 3)\n",
      "2562\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#import data\n",
    "workDir = '/mnt/c/users/llave/Documents/CMS/'\n",
    "#workDir = 'c:/users/llave/Documents/CMS/'\n",
    "data_match = np.load(workDir+'images_DYJets50_GEN_RECO_match.npy')\n",
    "data_no_match = np.load(workDir+'images_DYJets50_GEN_RECO_no_match.npy')\n",
    "classes = np.concatenate([np.ones(len(data_match)),np.zeros(len(data_no_match))])\n",
    "data = np.concatenate([data_match,data_no_match])\n",
    "print(data_match.shape,data_no_match.shape,data.shape)\n",
    "print(len(classes))\n",
    "\n",
    "#shuffle\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "classes = classes[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Embedding, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def build_discriminator(img_shape,n_classes=2):\n",
    "    input = Input(img_shape)\n",
    "    x = Conv2D(32*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(x)\n",
    "    x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
    "    x = (LeakyReLU(alpha=0.2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(128*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(256*3, kernel_size=(4,4), strides=(1,1), padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    # real/fake output\n",
    "    out1 = Dense(1, activation='sigmoid')(x)\n",
    "    # class label output\n",
    "    out2 = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, [out1, out2])\n",
    "    print(\"-- Discriminator -- \")\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def build_generator(latent_dim, n_classes=2):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # linear multiplication\n",
    "    n_nodes = 10 * 10\n",
    "    li = Dense(n_nodes, kernel_initializer=init)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((10, 10, 1))(li)\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # foundation for 10x10 image\n",
    "    n_nodes = 384 * 10 * 10\n",
    "    gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
    "    gen = Activation('relu')(gen)\n",
    "    gen = Reshape((10, 10, 384))(gen)\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li])\n",
    "    # upsample to 20x20\n",
    "    gen = Conv2DTranspose(192, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = Activation('relu')(gen)\n",
    "    # upsample to 40x40\n",
    "    gen = Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    "    out_layer = Activation('tanh')(gen)\n",
    "    # define model\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    print(\"-- Generator -- \")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#plots events\n",
    "def plot_event(eventNum):\n",
    "    \n",
    "    x = events[eventNum]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3)\n",
    "    for i in range(3):\n",
    "        axs[i].imshow(x[:,:,i])\n",
    "        \n",
    "    axs[0].set_title(\"ECAL\")\n",
    "    axs[1].set_title(\"HCAL\")\n",
    "    axs[2].set_title(\"Muon\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#generates and saves 5 random images\n",
    "def save_imgs(generator, epoch, batch):\n",
    "    r, c = 5, 3\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, j], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(workDir+\"images/ac_gan_%d_%d.png\" % (epoch, batch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def build_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect the outputs of the generator to the inputs of the discriminator\n",
    "    gan_output = d_model(g_model.output)\n",
    "    # define gan model as taking noise and label and outputting real/fake and label outputs\n",
    "    model = Model(g_model.input, gan_output)\n",
    "    # compile model\n",
    "    model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    print(\"-- GAN -- \")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Discriminator -- \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 40, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 20, 96)   4704        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 20, 20, 96)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 20, 96)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 192)  295104      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 11, 11, 192)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 11, 11, 192)  0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 11, 11, 192)  0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 11, 11, 192)  768         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 384)    1180032     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6, 6, 384)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 6, 384)    0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 6, 384)    1536        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 768)    4719360     batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 6, 6, 768)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 768)    0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 27648)        0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            27649       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            55298       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,284,451\n",
      "Trainable params: 6,283,299\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "-- Generator -- \n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 38400)        3878400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        100         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38400)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 100)       5100        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 10, 384)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 10, 1)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 10, 385)  0           reshape_2[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 192)  1848192     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 20, 192)  768         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20, 20, 192)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 3)    14403       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 40, 3)    0           conv2d_transpose_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 5,746,963\n",
      "Trainable params: 5,746,579\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "-- GAN -- \n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 38400)        3878400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        100         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38400)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 100)       5100        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 10, 384)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 10, 1)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 10, 385)  0           reshape_2[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 192)  1848192     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 20, 192)  768         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20, 20, 192)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 3)    14403       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 40, 3)    0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 1), (None, 2 6284451     activation_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 12,031,414\n",
      "Trainable params: 5,746,579\n",
      "Non-trainable params: 6,284,835\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "discriminator = build_discriminator(img_shape=(40,40, 3),n_classes=2)\n",
    "# create the generator\n",
    "generator = build_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  2562\n",
      "Number of Batches:  160\n",
      "Number of epochs:  100\n",
      "WARNING:tensorflow:From /home/llavezzo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llavezzo/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0, dr[1.114,1.114], df[0.689,0.479], g[0.778,2.922]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llavezzo/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 1, dr[1.057,1.057], df[0.753,0.002], g[0.941,2.878]\n",
      "epoch 0 batch 2, dr[0.250,0.250], df[0.722,0.006], g[0.896,1.894]\n",
      "epoch 0 batch 3, dr[0.628,0.628], df[0.905,0.007], g[0.846,3.248]\n",
      "epoch 0 batch 4, dr[0.376,0.376], df[1.330,0.008], g[1.537,2.253]\n",
      "epoch 0 batch 5, dr[0.559,0.559], df[1.807,0.023], g[1.006,1.171]\n",
      "epoch 0 batch 6, dr[0.380,0.380], df[0.914,0.243], g[0.829,1.515]\n",
      "epoch 0 batch 7, dr[0.401,0.401], df[0.861,0.036], g[0.714,1.961]\n",
      "epoch 0 batch 8, dr[0.324,0.324], df[0.810,0.008], g[0.272,3.298]\n",
      "epoch 0 batch 9, dr[0.355,0.355], df[1.236,0.003], g[1.296,3.624]\n",
      "epoch 0 batch 10, dr[0.236,0.236], df[0.801,0.001], g[1.304,2.743]\n",
      "epoch 0 batch 11, dr[0.320,0.320], df[0.804,0.005], g[1.081,2.664]\n",
      "epoch 0 batch 12, dr[0.217,0.217], df[0.893,0.007], g[0.152,1.446]\n",
      "epoch 0 batch 13, dr[0.261,0.261], df[2.044,0.009], g[0.759,1.907]\n",
      "epoch 0 batch 14, dr[0.461,0.461], df[0.825,0.016], g[1.739,0.863]\n",
      "epoch 0 batch 15, dr[0.947,0.947], df[1.180,0.013], g[0.231,1.628]\n",
      "epoch 0 batch 16, dr[0.261,0.261], df[1.454,0.131], g[0.271,1.789]\n",
      "epoch 0 batch 17, dr[0.208,0.208], df[1.026,0.008], g[1.151,1.544]\n",
      "epoch 0 batch 18, dr[0.349,0.349], df[0.643,0.006], g[1.325,3.120]\n",
      "epoch 0 batch 19, dr[0.521,0.521], df[0.796,0.007], g[0.270,2.764]\n",
      "epoch 0 batch 20, dr[0.344,0.344], df[1.927,0.001], g[0.934,2.242]\n",
      "epoch 0 batch 21, dr[0.652,0.652], df[0.854,0.011], g[2.093,2.193]\n",
      "epoch 0 batch 22, dr[0.163,0.163], df[1.500,0.148], g[0.285,0.504]\n",
      "epoch 0 batch 23, dr[0.251,0.251], df[1.749,0.007], g[0.366,2.444]\n",
      "epoch 0 batch 24, dr[0.217,0.217], df[0.447,0.020], g[1.889,0.470]\n",
      "epoch 0 batch 25, dr[0.244,0.244], df[1.796,0.011], g[0.288,3.577]\n",
      "epoch 0 batch 26, dr[0.321,0.321], df[2.761,0.032], g[0.480,1.420]\n",
      "epoch 0 batch 27, dr[0.215,0.215], df[1.443,0.179], g[0.520,1.740]\n",
      "epoch 0 batch 28, dr[0.548,0.548], df[0.642,0.075], g[0.420,2.592]\n",
      "epoch 0 batch 29, dr[0.240,0.240], df[0.418,0.004], g[0.365,3.306]\n",
      "epoch 0 batch 30, dr[0.512,0.512], df[0.582,0.003], g[1.542,1.765]\n",
      "epoch 0 batch 31, dr[0.524,0.524], df[1.468,0.027], g[1.157,3.560]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b105b7584b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy.random\n",
    "from numpy.random import choice\n",
    "from numpy.random import randn\n",
    "\n",
    "def noisy_labels(y, p_flip):\n",
    "    # determine the number of labels to flip\n",
    "    n_select = int(p_flip * y.shape[0])\n",
    "    # choose labels to flip\n",
    "    flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
    "    # invert the labels in place\n",
    "    y[flip_ix] = 1 - y[flip_ix]\n",
    "    return y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape((n_samples, latent_dim))\n",
    "    return x_input\n",
    "\n",
    "def smooth_positive_labels(y):\n",
    "    return y - 0.3 + (np.random.random(y.shape) * 0.5)\n",
    "\n",
    "def smooth_negative_labels(y):\n",
    "    return y + np.random.random(y.shape) * 0.3\n",
    "\n",
    "X_train = data\n",
    "y_train = classes\n",
    "\n",
    "epochs=100\n",
    "batch_size=16\n",
    "save_interval=1\n",
    "\n",
    "num_examples = X_train.shape[0]\n",
    "num_batches = int(num_examples / float(batch_size))\n",
    "print('Number of examples: ', num_examples)\n",
    "print('Number of Batches: ', num_batches)\n",
    "print('Number of epochs: ', epochs)\n",
    "\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "d_loss_array = []\n",
    "g_loss_array = []\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for batch in range(num_batches):\n",
    "\n",
    "        # noise images for the batch\n",
    "        noise = generate_latent_points(100,half_batch)\n",
    "        fake_classes = np.random.randint(0,2,size=half_batch)\n",
    "        fake_images = generator.predict([noise,fake_classes])\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "        # real images for batch\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        real_images = X_train[idx]\n",
    "        real_classes = y_train[idx]\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        \n",
    "        #noisy labels\n",
    "        real_labels = noisy_labels(real_labels,0.05)\n",
    "        real_labels = smooth_positive_labels(real_labels)\n",
    "        fake_labels = smooth_negative_labels(fake_labels)\n",
    "\n",
    "        # Train the discriminator (real classified as 1 and generated as 0)\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, [real_classes,real_labels])\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, [fake_classes,fake_labels])\n",
    "\n",
    "        # Train the generator\n",
    "        labels = np.ones((batch_size, 1))\n",
    "        classes = np.random.randint(0, 2, batch_size)\n",
    "        noise = generate_latent_points(100,batch_size)\n",
    "        \n",
    "        g_loss = gan_model.train_on_batch([noise,classes], [labels,classes])\n",
    "\n",
    "        \n",
    "        # Track the progress\n",
    "        if(batch % 50 == 0): \n",
    "            print('epoch %d batch %d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % \n",
    "              (epoch, batch, d_loss_real[1],d_loss_real[1], \n",
    "               d_loss_fake[1],d_loss_fake[2], g_loss[1],g_loss[2]))\n",
    "\n",
    "    \n",
    "    \n",
    "    save_imgs(generator, epoch, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
