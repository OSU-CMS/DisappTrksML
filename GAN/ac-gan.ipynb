{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8499\n",
      "(40, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "workDir = '/mnt/c/users/llave/Documents/CMS/'\n",
    "data = np.load(workDir+'images_DYJets50V2.npy')\n",
    "print(len(data))\n",
    "print(data[0].shape)\n",
    "\n",
    "data_x = data\n",
    "data_y = np.random.randint(2,size=data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Embedding, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def build_discriminator(img_shape,n_classes=2):\n",
    "    input = Input(img_shape)\n",
    "    x = Conv2D(32*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(x)\n",
    "    x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
    "    x = (LeakyReLU(alpha=0.2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(128*3, kernel_size=(4,4), strides=(2,2), padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(256*3, kernel_size=(4,4), strides=(1,1), padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    # real/fake output\n",
    "    out1 = Dense(1, activation='sigmoid')(x)\n",
    "    # class label output\n",
    "    out2 = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input, [out1, out2])\n",
    "    print(\"-- Discriminator -- \")\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def build_generator(latent_dim, n_classes=2):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # linear multiplication\n",
    "    n_nodes = 10 * 10\n",
    "    li = Dense(n_nodes, kernel_initializer=init)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((10, 10, 1))(li)\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # foundation for 10x10 image\n",
    "    n_nodes = 384 * 10 * 10\n",
    "    gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
    "    gen = Activation('relu')(gen)\n",
    "    gen = Reshape((10, 10, 384))(gen)\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li])\n",
    "    # upsample to 20x20\n",
    "    gen = Conv2DTranspose(192, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(merge)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = Activation('relu')(gen)\n",
    "    # upsample to 40x40\n",
    "    gen = Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
    "    out_layer = Activation('tanh')(gen)\n",
    "    # define model\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    print(\"-- Generator -- \")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#plots events\n",
    "def plot_event(eventNum):\n",
    "    \n",
    "    x = events[eventNum]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3)\n",
    "    for i in range(3):\n",
    "        axs[i].imshow(x[:,:,i])\n",
    "        \n",
    "    axs[0].set_title(\"ECAL\")\n",
    "    axs[1].set_title(\"HCAL\")\n",
    "    axs[2].set_title(\"Muon\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#generates and saves 5 random images\n",
    "def save_imgs(generator, epoch, batch):\n",
    "    r, c = 5, 3\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, j], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(workDir+\"images/ac_gan_%d_%d.png\" % (epoch, batch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def build_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect the outputs of the generator to the inputs of the discriminator\n",
    "    gan_output = d_model(g_model.output)\n",
    "    # define gan model as taking noise and label and outputting real/fake and label outputs\n",
    "    model = Model(g_model.input, gan_output)\n",
    "    # compile model\n",
    "    model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    print(\"-- GAN -- \")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Discriminator -- \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 40, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 20, 20, 96)   4704        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 20, 20, 96)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 20, 96)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 192)  295104      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 11, 11, 192)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 11, 11, 192)  0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 11, 11, 192)  0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 11, 11, 192)  768         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 6, 6, 384)    1180032     batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 6, 6, 384)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 6, 384)    0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 6, 384)    1536        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 768)    4719360     batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 6, 6, 768)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 768)    0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 27648)        0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            27649       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            55298       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,284,451\n",
      "Trainable params: 6,283,299\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/llavezzo/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "-- Generator -- \n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 38400)        3878400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        100         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38400)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 100)       5100        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 10, 384)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 10, 1)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 10, 385)  0           reshape_2[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 192)  1848192     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 20, 192)  768         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20, 20, 192)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 3)    14403       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 40, 3)    0           conv2d_transpose_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 5,746,963\n",
      "Trainable params: 5,746,579\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "-- GAN -- \n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 38400)        3878400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        100         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38400)        0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 100)       5100        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 10, 384)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 10, 1)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 10, 385)  0           reshape_2[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 192)  1848192     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20, 20, 192)  768         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20, 20, 192)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 3)    14403       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 40, 40, 3)    0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 1), (None, 2 6284451     activation_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 12,031,414\n",
      "Trainable params: 5,746,579\n",
      "Non-trainable params: 6,284,835\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "discriminator = build_discriminator(img_shape=(40,40, 3),n_classes=2)\n",
    "# create the generator\n",
    "generator = build_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  8499\n",
      "Number of Batches:  531\n",
      "Number of epochs:  100\n",
      "WARNING:tensorflow:From /home/llavezzo/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llavezzo/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/home/llavezzo/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0, dr[0.617,0.617], df[1.084,0.643], g[0.779,2.212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llavezzo/.local/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 1, dr[0.594,0.594], df[0.621,0.007], g[1.952,2.003]\n",
      "epoch 0 batch 2, dr[0.728,0.728], df[1.685,0.013], g[1.233,1.534]\n",
      "epoch 0 batch 3, dr[0.713,0.713], df[0.938,0.032], g[0.679,1.762]\n",
      "epoch 0 batch 4, dr[0.869,0.869], df[0.647,0.005], g[1.788,1.730]\n",
      "epoch 0 batch 5, dr[0.913,0.913], df[1.753,0.044], g[0.888,1.975]\n",
      "epoch 0 batch 6, dr[0.675,0.675], df[1.011,0.215], g[0.588,2.291]\n",
      "epoch 0 batch 7, dr[0.822,0.822], df[1.108,0.010], g[1.111,3.303]\n",
      "epoch 0 batch 8, dr[1.141,1.141], df[0.463,0.005], g[0.884,1.321]\n",
      "epoch 0 batch 9, dr[1.772,1.772], df[0.608,0.002], g[1.145,3.309]\n",
      "epoch 0 batch 10, dr[0.760,0.760], df[0.857,0.018], g[0.928,3.275]\n",
      "epoch 0 batch 11, dr[0.651,0.651], df[1.069,0.054], g[0.452,1.402]\n",
      "epoch 0 batch 12, dr[1.574,1.574], df[1.752,0.143], g[2.195,1.641]\n",
      "epoch 0 batch 13, dr[3.561,3.561], df[0.942,0.163], g[2.132,1.655]\n",
      "epoch 0 batch 14, dr[0.538,0.538], df[1.307,0.012], g[0.311,2.418]\n",
      "epoch 0 batch 15, dr[1.002,1.002], df[1.254,0.038], g[0.237,1.610]\n",
      "epoch 0 batch 16, dr[0.919,0.919], df[1.285,0.266], g[0.902,1.503]\n",
      "epoch 0 batch 17, dr[0.722,0.722], df[0.805,0.009], g[1.349,2.557]\n",
      "epoch 0 batch 18, dr[1.693,1.693], df[0.703,0.001], g[0.274,2.747]\n",
      "epoch 0 batch 19, dr[1.028,1.028], df[1.121,0.002], g[0.909,4.119]\n",
      "epoch 0 batch 20, dr[1.597,1.597], df[1.282,0.007], g[1.090,2.013]\n",
      "epoch 0 batch 21, dr[1.118,1.118], df[0.734,0.080], g[1.709,1.235]\n",
      "epoch 0 batch 22, dr[1.230,1.230], df[2.374,0.433], g[0.208,2.188]\n",
      "epoch 0 batch 23, dr[1.023,1.023], df[2.206,0.001], g[0.240,3.880]\n",
      "epoch 0 batch 24, dr[0.909,0.909], df[1.261,0.009], g[1.705,2.374]\n",
      "epoch 0 batch 25, dr[4.844,4.844], df[1.425,0.261], g[1.220,3.597]\n",
      "epoch 0 batch 26, dr[0.980,0.980], df[0.884,0.004], g[1.303,2.570]\n",
      "epoch 0 batch 27, dr[4.622,4.622], df[1.012,0.006], g[0.375,1.469]\n",
      "epoch 0 batch 28, dr[1.445,1.445], df[0.800,0.161], g[0.401,2.614]\n",
      "epoch 0 batch 29, dr[0.669,0.669], df[0.915,0.187], g[0.727,3.146]\n",
      "epoch 0 batch 30, dr[1.226,1.226], df[0.935,0.003], g[1.325,2.859]\n",
      "epoch 0 batch 31, dr[0.733,0.733], df[0.950,0.000], g[1.194,3.634]\n",
      "epoch 0 batch 32, dr[0.799,0.799], df[0.620,0.003], g[0.227,2.213]\n",
      "epoch 0 batch 33, dr[0.800,0.800], df[1.902,0.021], g[0.908,1.338]\n",
      "epoch 0 batch 34, dr[0.796,0.796], df[0.734,0.728], g[2.171,2.922]\n",
      "epoch 0 batch 35, dr[1.317,1.317], df[1.176,0.000], g[0.555,4.941]\n",
      "epoch 0 batch 36, dr[0.948,0.948], df[1.325,0.000], g[0.487,3.003]\n",
      "epoch 0 batch 37, dr[1.450,1.450], df[1.083,0.005], g[0.975,1.162]\n",
      "epoch 0 batch 38, dr[2.274,2.274], df[0.607,0.306], g[0.394,2.486]\n",
      "epoch 0 batch 39, dr[0.743,0.743], df[0.687,0.000], g[1.011,2.589]\n",
      "epoch 0 batch 40, dr[2.930,2.930], df[0.609,0.000], g[1.966,3.692]\n",
      "epoch 0 batch 41, dr[1.054,1.054], df[2.122,0.001], g[0.098,2.924]\n",
      "epoch 0 batch 42, dr[0.584,0.584], df[1.322,0.007], g[0.063,2.645]\n",
      "epoch 0 batch 43, dr[1.778,1.778], df[2.653,0.000], g[0.529,5.207]\n",
      "epoch 0 batch 44, dr[1.289,1.289], df[0.615,0.025], g[0.917,3.188]\n",
      "epoch 0 batch 45, dr[0.996,0.996], df[1.069,0.196], g[0.558,1.390]\n",
      "epoch 0 batch 46, dr[1.457,1.457], df[1.385,0.126], g[0.048,0.216]\n",
      "epoch 0 batch 47, dr[0.715,0.715], df[1.662,0.001], g[0.381,1.627]\n",
      "epoch 0 batch 48, dr[1.003,1.003], df[1.062,0.002], g[1.644,2.063]\n",
      "epoch 0 batch 49, dr[1.784,1.784], df[2.512,0.000], g[0.183,2.318]\n",
      "epoch 0 batch 50, dr[1.834,1.834], df[2.469,0.084], g[0.348,4.186]\n",
      "epoch 0 batch 51, dr[0.738,0.738], df[0.844,0.003], g[1.145,2.862]\n",
      "epoch 0 batch 52, dr[1.042,1.042], df[2.267,0.004], g[0.429,2.969]\n",
      "epoch 0 batch 53, dr[0.903,0.903], df[1.986,0.001], g[0.499,2.953]\n",
      "epoch 0 batch 54, dr[1.187,1.187], df[0.576,0.056], g[0.770,2.572]\n",
      "epoch 0 batch 55, dr[3.728,3.728], df[1.006,0.059], g[0.216,4.087]\n",
      "epoch 0 batch 56, dr[0.902,0.902], df[2.182,0.001], g[1.093,1.129]\n",
      "epoch 0 batch 57, dr[0.813,0.813], df[2.370,0.005], g[1.249,1.430]\n",
      "epoch 0 batch 58, dr[0.544,0.544], df[0.572,0.028], g[1.249,2.710]\n",
      "epoch 0 batch 59, dr[3.833,3.833], df[1.327,0.094], g[1.736,2.480]\n",
      "epoch 0 batch 60, dr[1.180,1.180], df[0.862,0.028], g[1.114,2.438]\n",
      "epoch 0 batch 61, dr[0.696,0.696], df[0.722,0.010], g[0.193,1.540]\n",
      "epoch 0 batch 62, dr[1.116,1.116], df[1.784,0.024], g[0.347,2.661]\n",
      "epoch 0 batch 63, dr[0.607,0.607], df[1.271,0.003], g[1.644,4.150]\n",
      "epoch 0 batch 64, dr[0.798,0.798], df[0.995,0.013], g[2.371,1.784]\n",
      "epoch 0 batch 65, dr[4.524,4.524], df[0.510,1.379], g[0.397,4.495]\n",
      "epoch 0 batch 66, dr[0.781,0.781], df[0.754,0.000], g[0.557,4.377]\n",
      "epoch 0 batch 67, dr[1.732,1.732], df[1.025,0.019], g[0.572,3.790]\n",
      "epoch 0 batch 68, dr[0.632,0.632], df[0.819,0.001], g[0.435,1.864]\n",
      "epoch 0 batch 69, dr[1.795,1.795], df[0.867,0.002], g[0.365,1.457]\n",
      "epoch 0 batch 70, dr[1.025,1.025], df[1.250,0.022], g[0.163,1.765]\n",
      "epoch 0 batch 71, dr[0.973,0.973], df[0.892,1.072], g[0.268,7.247]\n",
      "epoch 0 batch 72, dr[1.021,1.021], df[0.792,0.000], g[0.308,9.028]\n",
      "epoch 0 batch 73, dr[0.355,0.355], df[0.652,0.000], g[0.119,7.192]\n",
      "epoch 0 batch 74, dr[0.790,0.790], df[2.625,0.000], g[1.356,3.634]\n",
      "epoch 0 batch 75, dr[2.260,2.260], df[1.831,0.000], g[0.855,6.445]\n",
      "epoch 0 batch 76, dr[1.236,1.236], df[1.011,0.000], g[0.419,3.937]\n",
      "epoch 0 batch 77, dr[1.384,1.384], df[0.736,0.001], g[0.544,1.652]\n",
      "epoch 0 batch 78, dr[1.217,1.217], df[0.840,0.149], g[0.254,1.650]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-34fb5719af19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mfake_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy.random\n",
    "from numpy.random import choice\n",
    "from numpy.random import randn\n",
    "\n",
    "def noisy_labels(y, p_flip):\n",
    "    # determine the number of labels to flip\n",
    "    n_select = int(p_flip * y.shape[0])\n",
    "    # choose labels to flip\n",
    "    flip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n",
    "    # invert the labels in place\n",
    "    y[flip_ix] = 1 - y[flip_ix]\n",
    "    return y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape((n_samples, latent_dim))\n",
    "    return x_input\n",
    "\n",
    "def smooth_positive_labels(y):\n",
    "    return y - 0.3 + (np.random.random(y.shape) * 0.5)\n",
    "\n",
    "def smooth_negative_labels(y):\n",
    "    return y + np.random.random(y.shape) * 0.3\n",
    "\n",
    "X_train = data_x\n",
    "y_train = data_y\n",
    "\n",
    "epochs=100\n",
    "batch_size=16\n",
    "save_interval=1\n",
    "\n",
    "num_examples = X_train.shape[0]\n",
    "num_batches = int(num_examples / float(batch_size))\n",
    "print('Number of examples: ', num_examples)\n",
    "print('Number of Batches: ', num_batches)\n",
    "print('Number of epochs: ', epochs)\n",
    "\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "d_loss_array = []\n",
    "g_loss_array = []\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for batch in range(num_batches):\n",
    "\n",
    "        # noise images for the batch\n",
    "        noise = generate_latent_points(100,half_batch)\n",
    "        fake_classes = np.random.randint(0,2,size=half_batch)\n",
    "        fake_images = generator.predict([noise,fake_classes])\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "\n",
    "        # real images for batch\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        real_images = X_train[idx]\n",
    "        real_classes = y_train[idx]\n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        \n",
    "        #noisy labels\n",
    "        real_labels = noisy_labels(real_labels,0.05)\n",
    "        real_labels = smooth_positive_labels(real_labels)\n",
    "        fake_labels = smooth_negative_labels(fake_labels)\n",
    "\n",
    "        # Train the discriminator (real classified as 1 and generated as 0)\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, [real_classes,real_labels])\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, [fake_classes,fake_labels])\n",
    "\n",
    "        # Train the generator\n",
    "        labels = np.ones((batch_size, 1))\n",
    "        classes = np.random.randint(0, 2, batch_size)\n",
    "        noise = generate_latent_points(100,batch_size)\n",
    "        \n",
    "        g_loss = gan_model.train_on_batch([noise,classes], [labels,classes])\n",
    "\n",
    "        \n",
    "        # Track the progress\n",
    "        print('epoch %d batch %d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % \n",
    "              (epoch, batch, d_loss_real[1],d_loss_real[1], \n",
    "               d_loss_fake[1],d_loss_fake[2], g_loss[1],g_loss[2]))\n",
    "\n",
    "    \n",
    "    \n",
    "    save_imgs(generator, epoch, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(d_loss_array,label = 'D Loss')\n",
    "plt.plot(g_loss_array,label = 'G Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
